{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code has three sections.\n",
    "## 1. webscrapping flipkart and creating a dataframe. \n",
    "## 2. Calculating similarity between product description and input string. \n",
    "## 3. Generating rank results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/satishkumar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/satishkumar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Error loading corpus: Package 'corpus' not found in index\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from time import sleep\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('corpus')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1\n",
    "### This part of the code scraps flipkart and create dataframe with product name, price and other details\n",
    "#### Note: I've added sleep in combination with random to avoid flipkart blocking the ip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for i in tqdm(range(1,25)):\n",
    "    link = 'https://www.flipkart.com/clothing-and-accessories/topwear/pr?sid=clo,ash&p[]=facets.ideal_for%255B%255D%3DMen&p[]=facets.ideal_for%255B%255D%3Dmen&otracker=categorytree&fm=neo%2Fmerchandising&iid=M_a3234904-9e07-4535-a23f-7a2cf6a60d94_1_372UD5BXDFYS_MC.AHHHWF67UPNB&otracker=hp_rich_navigation_1_1.navigationCard.RICH_NAVIGATION_Fashion~Men%2527s%2BTop%2BWear~All_AHHHWF67UPNB&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_1_L2_view-all&cid=AHHHWF67UPNB'\n",
    "    if i !=1:\n",
    "        link = link+f'&page={i}'\n",
    "    page = requests.get(link)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    try:\n",
    "        for data in soup.findAll('div',class_=\"_13oc-S\"):\n",
    "            brand=data.find('div',class_=\"_2WkVRV\")\n",
    "            name=data.find('a',class_=\"IRpwTa\")\n",
    "            price = data.find('a',class_=\"_3bPFwb\")\n",
    "            hyperlink = data.find('a',class_=\"_2UzuFa\")\n",
    "            brand_list.append(brand.text)\n",
    "            product_name_list.append(name.text)\n",
    "            price_list.append(price.text.split('₹')[1])\n",
    "            discount_list.append(price.text.split('₹')[2].split('% off')[0][-2:])\n",
    "            hyperlink_list.append(\"https://www.flipkart.com\"+hyperlink['href'])\n",
    "    except:\n",
    "        brand_list.append(' ')\n",
    "        product_name_list.append(' ')\n",
    "        price_list.append(' ')\n",
    "        discount_list.append(' ')\n",
    "        hyperlink_list.append(' ')\n",
    "    page.close()\n",
    "    interval = 10+random()*5\n",
    "    sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "men_topwear = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "men_topwear.drop_duplicates(['product_name'],inplace=True)\n",
    "men_topwear.reset_index(inplace=True,drop=True)\n",
    "men_topwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for i in tqdm(range(1,25)):\n",
    "    link = 'https://www.flipkart.com/clothing-and-accessories/bottomwear/pr?sid=clo%2Cvua&otracker=categorytree&p%5B%5D=facets.ideal_for%255B%255D%3DMen&otracker=nmenu_sub_Men_0_Bottom%20wear'\n",
    "    if i !=1:\n",
    "        link = link+f'&page={i}'\n",
    "    page = requests.get(link)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    try:\n",
    "        for data in soup.findAll('div',class_=\"_13oc-S\"):\n",
    "            brand=data.find('div',class_=\"_2WkVRV\")\n",
    "            name=data.find('a',class_=\"IRpwTa\")\n",
    "            price = data.find('a',class_=\"_3bPFwb\")\n",
    "            hyperlink = data.find('a',class_=\"_2UzuFa\")\n",
    "            brand_list.append(brand.text)\n",
    "            product_name_list.append(name.text)\n",
    "            price_list.append(price.text.split('₹')[1])\n",
    "            discount_list.append(price.text.split('₹')[2].split('% off')[0][-2:])\n",
    "            hyperlink_list.append(\"https://www.flipkart.com\"+hyperlink['href'])\n",
    "    except:\n",
    "        brand_list.append(' ')\n",
    "        product_name_list.append(' ')\n",
    "        price_list.append(' ')\n",
    "        discount_list.append(' ')\n",
    "        hyperlink_list.append(' ')\n",
    "    page.close()\n",
    "    interval = 10+random()*5\n",
    "    sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "men_bottomwear = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "men_bottomwear.drop_duplicates(['product_name'],inplace=True)\n",
    "men_bottomwear.reset_index(inplace=True,drop=True)\n",
    "men_bottomwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for i in tqdm(range(1,25)):\n",
    "    link = 'https://www.flipkart.com/clothing-and-accessories/topwear/pr?sid=clo,ash&p[]=facets.ideal_for%255B%255D%3DWomen&p[]=facets.ideal_for%255B%255D%3Dwomen&otracker=categorytree&otracker=nmenu_sub_Women_0_Topwear'\n",
    "    if i !=1:\n",
    "        link = link+f'&page={i}'\n",
    "    page = requests.get(link)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    try:\n",
    "        for data in soup.findAll('div',class_=\"_13oc-S\"):\n",
    "            brand=data.find('div',class_=\"_2WkVRV\")\n",
    "            name=data.find('a',class_=\"IRpwTa\")\n",
    "            price = data.find('a',class_=\"_3bPFwb\")\n",
    "            hyperlink = data.find('a',class_=\"_2UzuFa\")\n",
    "            brand_list.append(brand.text)\n",
    "            product_name_list.append(name.text)\n",
    "            price_list.append(price.text.split('₹')[1])\n",
    "            discount_list.append(price.text.split('₹')[2].split('% off')[0][-2:])\n",
    "            hyperlink_list.append(\"https://www.flipkart.com\"+hyperlink['href'])\n",
    "    except:\n",
    "        price_list.append(' ')\n",
    "        discount_list.append(' ')\n",
    "        hyperlink_list.append(' ')\n",
    "    page.close()\n",
    "    interval = 10+random()*5\n",
    "    sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "women_topwear = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "women_topwear.drop_duplicates(['product_name'],inplace=True)\n",
    "women_topwear.reset_index(inplace=True,drop=True)\n",
    "women_topwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for i in tqdm(range(1,25)):\n",
    "    link = 'https://www.flipkart.com/womens-jeans/pr?sid=clo%2Cvua%2Ck58%2C4hp&otracker[]=categorytree&otracker[]=nmenu_sub_Women_0_Jeans'\n",
    "    if i !=1:\n",
    "        link = link+f'&page={i}'\n",
    "    page = requests.get(link)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    try:\n",
    "        for data in soup.findAll('div',class_=\"_13oc-S\"):\n",
    "            brand=data.find('div',class_=\"_2WkVRV\")\n",
    "            name=data.find('a',class_=\"IRpwTa\")\n",
    "            price = data.find('a',class_=\"_3bPFwb\")\n",
    "            hyperlink = data.find('a',class_=\"_2UzuFa\")\n",
    "            brand_list.append(brand.text)\n",
    "            product_name_list.append(name.text)\n",
    "            price_list.append(price.text.split('₹')[1])\n",
    "            discount_list.append(price.text.split('₹')[2].split('% off')[0][-2:])\n",
    "            hyperlink_list.append(\"https://www.flipkart.com\"+hyperlink['href'])\n",
    "    except:\n",
    "        price_list.append(' ')\n",
    "        discount_list.append(' ')\n",
    "        hyperlink_list.append(' ')\n",
    "    page.close()\n",
    "    interval = 10+random()*5\n",
    "    sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "women_jeans = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "women_jeans.drop_duplicates(['product_name'],inplace=True)\n",
    "women_jeans.reset_index(inplace=True,drop=True)\n",
    "women_jeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all dataframes in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing = pd.concat([men_topwear,men_bottomwear,women_topwear,women_jeans])\n",
    "clothing.reset_index(drop=True,inplace=True)\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing.to_csv('clothing.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "### This part defines a function which computes similarity between two strings using TF IDF vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing = pd.read_csv('clothing.csv')\n",
    "stopwords = stopwords.words('english') \n",
    "punctuation_removal = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def preprocess(text):\n",
    "    return nltk.word_tokenize(text.lower().translate(punctuation_removal))\n",
    "vectorizer = TfidfVectorizer(tokenizer=preprocess, stop_words=stopwords)\n",
    "\n",
    "def compute_similarity(a, b):\n",
    "    tfidf = vectorizer.fit_transform([a, b])\n",
    "    return ((tfidf * tfidf.T).toarray())[0,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3\n",
    "### Finally the function below calls the TF IDF vectorizer and gives N top matching product links\n",
    "\n",
    "#### Note: by combining price and discount with product description we can tackle string which mentions prices and discount criteria as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloths_list(input_string,N):\n",
    "    clothing['similarity_score'] = ''\n",
    "    for i in range(len(clothing)):\n",
    "        clothing['similarity_score'].iloc[i]=compute_similarity(input_string,clothing['product_name'][i])\n",
    "    df_n = clothing[['product_name','similarity_score','link']]\n",
    "    df1=df_n[df_n['similarity_score'] > 0.3].sort_values(by=['similarity_score'],ascending=False)['link']\n",
    "    df1.reset_index(drop=True,inplace=True)\n",
    "    if N>len(df1):\n",
    "        return df1\n",
    "    else:\n",
    "        return df1[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satishkumar/opt/anaconda3/envs/OCR/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'thatll', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                              https://www.flipkart.com/killer-skinny-men-black-jeans/p/itm35c95c3f6ecc8?pid=JEAGGVXEEA8Y2C9Z&lid=LSTJEAGGVXEEA8Y2C9ZJ948KV&marketplace=FLIPKART&store=clo%2Fvua&srno=b_10_373&otracker=browse&fm=organic&iid=c8839ac1-04ff-4a0b-bd19-c36c9e67e4ab.JEAGGVXEEA8Y2C9Z.SEARCH&ppt=None&ppn=None&ssid=0wxse840000000001684583616079\n",
       "1                                         https://www.flipkart.com/flying-machine-slim-men-black-jeans/p/itme057735870ef7?pid=JEAG8N3YVSDGSDFY&lid=LSTJEAG8N3YVSDGSDFY4DMNIL&marketplace=FLIPKART&store=clo%2Fvua&srno=b_7_249&otracker=browse&fm=organic&iid=f5fe4024-9ed9-4f8f-839c-3887d9c83432.JEAG8N3YVSDGSDFY.SEARCH&ppt=None&ppn=None&ssid=jjy3mlj9n40000001684583577011\n",
       "2                                          https://www.flipkart.com/spykar-super-skinny-men-black-jeans/p/itm05d05c64a1e00?pid=JEAGMAPFYVNV9RSZ&lid=LSTJEAGMAPFYVNV9RSZHWWARL&marketplace=FLIPKART&store=clo%2Fvua&srno=b_3_93&otracker=browse&fm=organic&iid=ba508d50-004f-4795-ac10-3ccaafb5c0a3.JEAGMAPFYVNV9RSZ.SEARCH&ppt=None&ppn=None&ssid=c3lvuvbc5s0000001684583519472\n",
       "3    https://www.flipkart.com/unbeatable-solid-men-black-tights/p/itmb2206ad42c102?pid=TGTGH63MQFP9VAVR&lid=LSTTGTGH63MQFP9VAVRYKLMW0&marketplace=FLIPKART&store=clo%2Fvua&srno=b_5_181&otracker=browse&fm=organic&iid=en_tD4HGpPjpwLxIG%2BJfs0RXVfAT4G2OHwnceLTL7PlyHDtjIMV69thXUw7Np8bj3Rm9ta9aE2qwSCeYTC%2BpgYQhQ%3D%3D&ppt=None&ppn=None&ssid=005sb05rgw0000001684583549908\n",
       "4                                          https://www.flipkart.com/adidas-solid-men-black-track-pants/p/itm7e60c30b7e26d?pid=TKPFVEUHNJYBZFQR&lid=LSTTKPFVEUHNJYBZFQRP8KHVX&marketplace=FLIPKART&store=clo%2Fvua&srno=b_9_345&otracker=browse&fm=organic&iid=c0b8b543-6114-4ed4-8fb6-5f6d143e040e.TKPFVEUHNJYBZFQR.SEARCH&ppt=None&ppn=None&ssid=gc3ynw3uj40000001684583603512\n",
       "Name: link, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = cloths_list(\"men black jeans\",5)\n",
    "pd.set_option('max_colwidth', None)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other webscrapping script which didn't perform as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://www.myntra.com/men-topwear'\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'}\n",
    "\n",
    "s = requests.Session()\n",
    "res = s.get(link, headers=headers, verify=False)\n",
    "\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "script = None\n",
    "for s in soup.find_all(\"script\"):\n",
    "    if 'pdpData' in s.text:\n",
    "        script = s.get_text(strip=True)\n",
    "        break\n",
    "\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for i in tqdm(range(1,25)):\n",
    "    link = 'https://www.myntra.com/men-topwear'\n",
    "    if i !=1:\n",
    "        link = link+f'?p={i}'\n",
    "    print(link)\n",
    "    page = requests.get(link)\n",
    "    soup = bs(page.content, 'html.parser')\n",
    "    try:\n",
    "        for data in soup.findAll('div',class_=\"product-productMetaInfo\"):\n",
    "            brand=data.find('h3',class_=\"product-brand\")\n",
    "            name=data.find('h4',class_=\"product-product\")\n",
    "            price = data.find('span',class_=\"product-discountedPrice\")\n",
    "            discount = data.find('span',class_=\"product-discountedPercentage\")\n",
    "            hyperlink = data.find('a',target=\"_blank\")\n",
    "            brand_list.append(brand.text)\n",
    "            product_name_list.append(name.text)\n",
    "            price_list.append(price.text.split('Rs')[1])\n",
    "            discount_list.append(discount)\n",
    "            hyperlink_list.append(\"https://www.myntra.com/\"+hyperlink['href'])\n",
    "    except:\n",
    "        brand_list.append(' ')\n",
    "        product_name_list.append(' ')\n",
    "        price_list.append(' ')\n",
    "        discount_list.append(' ')\n",
    "        hyperlink_list.append(' ')\n",
    "    page.close()\n",
    "    interval = 10+random()*5\n",
    "    sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "myntra_men_topwear = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "myntra_men_topwear.drop_duplicates(['product_name'],inplace=True)\n",
    "myntra_men_topwear.reset_index(inplace=True,drop=True)\n",
    "myntra_men_topwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = 'https://www.flipkart.com/clothing-and-accessories/topwear/pr?sid=clo,ash&p[]=facets.ideal_for%255B%255D%3DMen&p[]=facets.ideal_for%255B%255D%3Dmen&otracker=categorytree&fm=neo%2Fmerchandising&iid=M_172efac0-36c7-47fd-9d35-94ad57f9f0d9_1_372UD5BXDFYS_MC.6XNZG1FYFBZT&otracker=hp_rich_navigation_1_1.navigationCard.RICH_NAVIGATION_Fashion~Men%2527s%2BTop%2BWear_6XNZG1FYFBZT&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_1_L1_view-all&cid=6XNZG1FYFBZT'\n",
    "link2 = 'https://www.flipkart.com/clothing-and-accessories/bottomwear/pr?sid=clo,vua&p[]=facets.ideal_for%255B%255D%3DMen&p[]=facets.ideal_for%255B%255D%3Dmen&otracker=categorytree&fm=neo%2Fmerchandising&iid=M_172efac0-36c7-47fd-9d35-94ad57f9f0d9_1_372UD5BXDFYS_MC.8HARX8UX7IX5&otracker=hp_rich_navigation_2_1.navigationCard.RICH_NAVIGATION_Fashion~Men%2527s%2BBottom%2BWear_8HARX8UX7IX5&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_2_L1_view-all&cid=8HARX8UX7IX5'\n",
    "link3 = 'https://www.flipkart.com/clothing-and-accessories/~cs-aerg0b0afc/pr?sid=clo&collection-tab-name=KK%2CSets%2CDM%2CSarees&fm=neo%2Fmerchandising&iid=M_172efac0-36c7-47fd-9d35-94ad57f9f0d9_1_372UD5BXDFYS_MC.HQXTE43PO8HC&otracker=hp_rich_navigation_3_1.navigationCard.RICH_NAVIGATION_Fashion~Women%2BEthnic_HQXTE43PO8HC&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_3_L1_view-all&cid=HQXTE43PO8HC'\n",
    "link4 = 'https://www.flipkart.com/clothing-and-accessories/~cs-ahd69o77qf/pr?sid=clo&collection-tab-name=Western+Wear&fm=neo%2Fmerchandising&iid=M_172efac0-36c7-47fd-9d35-94ad57f9f0d9_1_372UD5BXDFYS_MC.K4M2S29QJWT9&otracker=hp_rich_navigation_4_1.navigationCard.RICH_NAVIGATION_Fashion%7EWomen%2BWestern_K4M2S29QJWT9&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_4_L1_view-all&cid=K4M2S29QJWT9&page=2' \n",
    "links = [link1,link2,link3,link4]\n",
    "brand_list=[]\n",
    "product_name_list=[]\n",
    "price_list=[]\n",
    "discount_list=[]\n",
    "hyperlink_list=[]\n",
    "for link in links:\n",
    "    for i in tqdm(range(1,30)):\n",
    "        if i !=1:\n",
    "            link = link+f'&page={i}'\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "        try:\n",
    "            for data in soup.findAll('div',class_=\"_13oc-S\"):\n",
    "                brand=data.find('div',class_=\"_2WkVRV\")\n",
    "                name=data.find('a',class_=\"IRpwTa\")\n",
    "                price = data.find('a',class_=\"_3bPFwb\")\n",
    "                hyperlink = data.find('a',class_=\"_2UzuFa\")\n",
    "                brand_list.append(brand.text)\n",
    "                product_name_list.append(name.text)\n",
    "                price_list.append(price.text.split('₹')[1])\n",
    "                discount_list.append(price.text.split('₹')[2].split('% off')[0][-2:])\n",
    "                hyperlink_list.append(\"https://www.flipkart.com\"+hyperlink['href'])\n",
    "        except:\n",
    "            price_list.append(' ')\n",
    "            discount_list.append(' ')\n",
    "            hyperlink_list.append(' ')\n",
    "        page.close()\n",
    "        interval = 20+random()*10\n",
    "        sleep(interval)\n",
    "l = list([brand_list,product_name_list,price_list,discount_list,hyperlink_list])\n",
    "new_clothing = pd.DataFrame(np.array(l).transpose(),columns=['brand','product_name','price','discount','link'])\n",
    "new_clothing.drop_duplicates(['product_name'],inplace=True)\n",
    "new_clothing.reset_index(inplace=True,drop=True)\n",
    "new_clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
